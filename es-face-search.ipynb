{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face search demo using Amazon ES knn and machine learning.\n",
    "\n",
    "High level steps:\n",
    "\n",
    "1. face detection and feature extraction\n",
    "2. feature vector index in ES\n",
    "3. 1:N vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect face and extact features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import os.path\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(train_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    img_paths = []\n",
    "\n",
    "    # Loop through each person in the training set\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        # Loop through each training image for the current person\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_bounding_boxes = face_recognition.face_locations(image)\n",
    "\n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                # If there are no people (or too many people) in a training image, skip the image.\n",
    "                print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
    "            else:\n",
    "                # Add face encoding for current image to the training set\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "                img_paths.append(img_path)\n",
    "        \n",
    "    return X, y, img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the Elasticsearch connection\n",
    "import boto3\n",
    "from elasticsearch import Elasticsearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "region = 'ap-southeast-1'\n",
    "service = 'es'\n",
    "es_host = 'search-winston-elasti-2lknspawyv4c-ftmwkbcikgrs7kkah7grjwvoay.ap-southeast-1.es.amazonaws.com'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts = [{'host': es_host, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define KNN Elasticsearch index maping\n",
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"face_img_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 128\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#Creating the Elasticsearch index\n",
    "es.indices.create(index=\"idx_faces\",body=knn_index,ignore=400)\n",
    "es.indices.get(index=\"idx_faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build knn index in ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"train\"\n",
    "vectors, names, img_paths = extract_features(TRAIN_DIR)\n",
    "print(names)\n",
    "print(img_paths)\n",
    "print(len(vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def es_import(i):\n",
    "    es.index(index='idx_faces',\n",
    "             body={\"face_img_vector\": i[0], \n",
    "                   \"name\": i[1],\n",
    "                   \"img_path\": i[2]}\n",
    "            )\n",
    "\n",
    "for vector, name, img_path in zip(vectors, names, img_paths):\n",
    "    # print(vector, name)\n",
    "    es_import([vector, name, img_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = es.delete_by_query(index=\"idx_faces\", body={\"query\": {\"match_all\": {}}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1:N face search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg \n",
    "\n",
    "def display_img(img_path):\n",
    "    image = plt.imread(img_path)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "    \n",
    "test_img_path = 'test/obama2.jpg'\n",
    "display_img(test_img_path)\n",
    "\n",
    "image = face_recognition.load_image_file(test_img_path)\n",
    "face_bounding_boxes = face_recognition.face_locations(image)\n",
    "\n",
    "face_feature = face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "idx_name = 'idx_faces'\n",
    "res = es.search(request_timeout=30, index=idx_name,\n",
    "                body={'size': k, \n",
    "                      'query': {'knn': {'face_img_vector': {'vector': face_feature, 'k': k}}}})\n",
    "print(\"Return top 1 with score: %s\" % res['hits']['max_score'])\n",
    "\n",
    "# print(res)\n",
    "DISTANCE_THRESHHOLD = 0.8\n",
    "if (res['hits']['hits'][0]['_score'] >= DISTANCE_THRESHHOLD):\n",
    "    print(\"Found %s\" % res['hits']['hits'][0]['_source']['name'])\n",
    "    display_img(res['hits']['hits'][0]['_source']['img_path'])\n",
    "else:\n",
    "    print(\"No faces found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = es.search(index=\"idx_faces\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595228709538",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}